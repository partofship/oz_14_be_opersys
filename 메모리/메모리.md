
### 메모리

---

저장 자원: CPU가 직접 접근해 데이터를 읽고 쓰는 저장 자원

- 계층 구조: 하단 참조
- 실행 상태에 있는 프로세스: 반드시 메인 메모리에 적재.
- 실행되지 않는 프로세스: 보조 기억장치의 스왑 영역에 저장
- 스와핑: 프로세스의 상태 변화에 따라 메인 메모리 ↔ 보조 저장장치 사이에서 교환/이동
- 메모리 할당 방식: 고정 분할/가변 분할
    - 운영 체제는 여러 개의 프로세스를 메모리에 올려야 한다.
    - 이 때 메모리 할당 방식을 사용해 프로세스마다 필요한 공간을 배정함.
    - 고정 분할 방식
        - 메모리를 미리 일정한 크기로 자름 → 각 프로세스에 하나의 분할 영역을 할당하는 방식
        - 구현은 단순
        - 프로세스 크기와 분할 크기가 맞지 않으면? ▷ `내부 단편화` 발생 = 메모리 낭비 ↑
    - 가변 분할 방식
        - 프로세스 크기에 맞춰 메모리 공간을 동적으로 할당 (=그때그때)
        - 메모리 활용률 ↑ (Compare to 고정 분할)
        - 외부 단편화가 발생 염려
    - `외부 단편화`?
       - 가변 분할 방식에서 보통 발생.
       - 상황: 메모리에 사용 가능한 총 공간은 존재하는데 (1~10) 연속된 큰 블록이 부족해 새 프로세스를 적재하지 못함
       - (4 정도 사이즈 되는 것이 들어가야 하는데, 1~3/ 4공란 5공란 6공란 7 사용 8공란 9공란 10공란 이런식)
       - 해결법: 메모리 압축 / `가상 메모리 기법`

---

가상 메모리: 실제 물리 메모리RAM의 크기보다 큰 프로세스를 실행할 수 있게 만듬
- 당장 필요한 부분(프로세스)만 RAM 적재 ▷ 나머지는 보조기억장치에 보관
- 사용자/프로그램: 매우 큰 연속 메모리 사용하는 것처럼 인식
- 실제: OS가 물리 메모리/디스크 공간 함께 사용해 `가상 주소 공간`을 제공
- 페이징 기법
    - 가상 메모리 구현하는 고정 분할 기반 방식
    - 논리 주소 공간 | 물리 주소 공간   나눌 때 모두 동일한 크기의 블록으로
    - 논리 주소 공간의 단위를 `페이지`
    - 물리 주소 공간의 단위를 `프레임` (물리프리 논리책)
    - 각 프로세스의 페이지(논리 주소 공간 블록) → 메인 메모리의 프레임(물리)에 불연속 할당될 수 있음
    - 연속되게 보이고 싶겠지? 연속된 주소로 보이기 위해 페이지 테이블을 통해 주소 변환 발생
    - 주소를 통해 참조 참조 참조 된다는 소리인가?
    - 외부 단편화는 해결하지만, Issue: 페이지 크기보다 작은 데이터 남으면 ▷ `내부 단편화`

---

페이지 테이블 레지스터
- 현재 실행 중인 프로세스의 페이지 테이블이 메모리의 어디에 있음? 알려주는 레지스터
- CPU는 논리 주소 → 물리 주소로 변환 때 해당 레지스터를 기준으로 페이지 테이블 엔트리를 참조
- 1 페이지 테이블 엔트리 = 해당 페이지의 N개 속성 저장
- 속성: 접근 비트, 변경 비트, 유효 비트, 보호 비트
    - 접근 비트: 해당 페이지가 메모리에 올라온 이후 실제로 참조된 적이 있는지 나타냄
    - 변경 비트: 페이지의 내용이 수정되었는가? 나타냄. 페이지가 디스크로 내려갈 때 다시 기록해야 하는가? 결정 기준
    - 유효 비트: 해당 페이지는 현재 메인 메모리에 존재하는가? 디스크에 존재하는가? 나타냄
    - 보호 비트: 페이지에 대한 읽기/쓰기/실행 권한 지정 → 메모리 보호 기능 수행

---

페이지드 세그멘테이션
- 가상 메모리 관리 방식 = 세그멘테이션 + 페이징 기법(둘을 결합)
- 프로그램의 논리 구조에 따라 분할 = 코드 | 데이터 | 스택 (이런 세그먼트로 분할)
- 각 세그먼트를 다시 일정한 크기의 페이지로 나누어 관리
- 장점: 세그멘테이션의 논리적 구조 반영. 페이징의 외부 단편화 제거
- 단점: 주소 변환 과정 복잡. 관리 비용 ↑
- 이런 메모리 관리 비법: 한정된 물리 메모리 자원을 다수의 프로세스가 안정적으로 공유하기 위한 핵심 기술.
- 시스템 성능, 안정성, 확장성에 영향을 미침

### 메모리의 계층 구조

---

- 계층 구조: 속도, 용량, 비용 차이에 따라 계층 구조로 구성. 레지스터, 캐시, 메인 메모리(RAM), 보조기억장치
- 레지스터: CPU 내부에 위치, Quickest, 용량 극히 작음
- 캐시 메모리(L1,L2,L3)
    - 고속 완충 장치: 주기억장치 접근 지연을 줄이기 위해
    - 지역성 원리, L1-L2-L3 설계, 캐시히트/캐시미스, 캐시 일관성, 쓰기 방식(반영 방식)
    - <details> <summary>상세</summary>
        
        - CPU - RAM 사이 위치하는 고속 완충 저장 장치.
        - 메모리 접근 지연Latency 최소화 → 전체 시스템 성능 ↑
        - 지역성Locality 원리 기반으로 동작: 시간적/공간적
        - 두 성질을 이용해 프로그램 실행 시 반복적으로 참조되는 코드와 데이터 우선적으로 저장
            - 시간적 지역성: 최근 사용한 데이터가 가까운 미래에도 다시 사용될 가능성이 크다
            - 공간적 지역성: 어떤 메모리 주소가 접근 → 인접 주소도 곧 접근될 가능성이 크다
        - L1,L2,L3 캐시: 속도·용량·비용 균형을 고려해 설계
            - L1: CPU 내부 존재. 가장 빠른 접근 속도, 용량 매우 작음
            - L2: L1과 L2 사이 ▷ L1보다 느리지만 용량 더 크며, L3보다 빠르지만 용량 작음. 코어별로 분리되어 있거나/공유되거나
            - L3: 여러 코어가 공유하는 형태. 가장 느린 접근 속도, 용량 가장 큼.
        - CPU가 접근하는 순서: L1 (캐시 히트) → L2  → L3 → 없을 시 메인 메모리에서 데이터 가져옴(캐시 미스)
        - 캐시 미스일 경우 메모리 접근 지연 ↑
        - 캐시 히트율이 좋아야겠지? 히트율 높을수록 CPU는 대기 없이 연산 수행
        - 캐시 일관성
            - 멀티코어에서 중요
            - 각 캐시 라인의 상태를 공유/수정/무효화 등의 상태로 관리해 모든 코어가 동일한 메모리 값을 보도록 보장함
            - 여러 개의 CPU가 각자 독립된 캐시 보유 시, 한 코어가 데이터 수정 → 다른 코어의 (캐시에 저장된) 동일 데이터와 불일치 발생
            - 이를 방지하기 위해 캐시 일관성 프로토콜 사용(예: MESI) → 상태를 관리
        - 쓰기 방식에 따른 구분: Write Through, Write Back
            - Write Through: 캐시 쓰기 연산 발생 → 메인 메모리(RAM)에도 즉시 반영
            - Write Back: 캐시 쓰기 연산 발생 → 우선 캐시에만 반영 → 캐시 라인 교체될 때 메인 메모리에 반영
            - 데이터 일관성 높음(Good), 메모리 접근 회수 증가(Bad) VS 성능 우수(Good), 데이터 손실 위험 - 전원 장애(Bad)

    </details>

- 메인 메모리
    - 실행 중인 프로그램과 데이터를 저장하는 공간

---

- 보조기억장치
    - 전원이 꺼져도 데이터가 유지되는 대용량 저장 장치

### 요구 페이징, 페이지 폴트, 프리 페칭, 페이지 교체 정책

---

요구 페이징
- 가상 메모리 환경상에서 실제 접근 발생하는 페이지만 필요 시점에 메모리에 적재
- (프로세스의 모든 페이지를 한 번에 메인 메모리에 적재 X)
- 메모리에 과도한 부담이 되는 문제를 해결
- 실제 프로그램: 극히 일부 코드, 데이터만 반복적으로 참조
- ∴) 프로그램의 위와 같은 접근 특성 활용해, 실제로 필요한 페이지만 메모리에 적재 = 제한된 물리 메모리 자원을 다수의 프로세스가 동시에 공유

<details>

> 요구 페이징은 단순한 [필요한 페이지만 적재]라는 개념을 넘어,
> - 페이지 폴트의 종류
> - 프레임 할당 정책
> - LRU 근사 알고리즘
> - 프리페칭
> - 다중 프로그래밍 정도 제어
> - 워킹 셋
> - PFF 기반 제어 등
>
> 다층적인 운영체제 내부 메커니즘과 결합되어 정밀하게 동작하는 메모리 관리 체계이다. 이 모든 요소는 제한된 물리 메모리 자원으로 최대의 처리량과 안정성을 확보하기 위해 상호 연동되어 설계된다.

++ (스왑 영역이 위치한) 저장 장치의 성능이 낮을수록 = 페이지 폴트 처리 비용 증가.<br>
그래서 HDD 대신 SSD를 스왑 영역으로 사용하는 것이 일반적임.<br>
특히, 서버 환경에서는 스와핑 자체를 최소화하도록 메모리 용량 충분히 확보하는 설계 진행

</details>

<b>페이지 폴트Page Fault</b>

- CPU가 페이지에 접근하는 명령어 실행했을 때, 해당 페이지가 1) 메인 메모리에 존재하지 않고 2) 보조저장장치에 있는 경우 즉시 실행 불가 → 페이지 폴트 예외 발생
- 발생 시, OS는 실행 중인 프로세스를 일시 중단 → 해당 페이지: from 보조 저장장치 ▶ 메인 메모리로 가져오는 작업 실행 (스와핑 작업)
- 프로세스 실행 재개
- 장점: 메모리 자원 사용 최소화, 시스템 효율 ↑

- 메이저 vs 마이너
    - 페이지 폴트는 모두 동일한 비용? No
    - 메이저: 요청된 페이지: 디스크 스왑 영역에 존재 → 실제 디스크 I/O 발생하는 경우
        - 지연 발생: 수 밀리초 단위
    - 마이너: 이미 메인 메모리에 올라와 있으나 해당 프로세스의 페이지 테이블에 반영되지 않음
        - 디스크 접근 없이 페이지 테이블 갱신만 수행 → 비용매우 낮음
    - 따라서 OS는 메이저 페이지 폴트 빈도 최소화를 목표로 함 (성능 업그레이드 시)

--- 
<b>프리 페칭</b>
- 공간적 지역성 이용: 현재 접근된 페이지에 인접한 페이지가 곧 사용될 가능성이 크다.
- 실제 요청이 오기 전 여러 개 페이지를 메모리에 <b>미리</b> 적재
- 장점: 페이지 폴트의 발생 자체를 사전에 줄임
- 단점: 예측 잘못되면? 예측 잘못 반복 → 불필요한 스와핑 증가 = 성능 저하

---

<b>페이지 교체 정책</b>

- 조건
    - 새로운 페이지를 적재해야 함
    - 메인 메모리가 가득 찬 상황
    - 어떤 페이지를 제거할지
- 정책 방식: 선입선출FIFO, 최적 페이지 교체, LRU

- <details> <summary> 상세 </summary>

    - 선입선출: (선착순) 가장 먼저 메모리에 들어온 페이지 가장 먼저 교체
        - 구현하기 쉽지만 비효율 발생 가능 (페이지 접근 패턴을 고려 X)
    - 최적 페이지 교체: 가장 오랫동안 사용되지 않을 페이지 교체
        - 이론상 가장 이상적
        - 미래의 접근 순서 알 수 없음 → 실제 시스템에서 직접 구현하기 어려움. 성능 비교 기준으로만 사용
    - LRU: Least Recently Used. 가장 오랫동안 사용되지 않은 페이지 교체하는 방식
        - 최근 사용 이력 기반으로 판단. 실제 실행 환경의 지역성 특성 잘 반영 → 널리 사용됨
        - 이론적으론 지역성 가장 잘 반영하지만...정확한 구현은 어려움
        - 어려움 = 비용이 크다. 모든 페이지 접근 시점을 기록해야 하기 때문에 하드웨어적, 소프트웨어적 비용 높음
        - 실제 시스템: LRU 근사 알고리즘 (Clock, NRU: Not really Used)
        - 접근 비트, 변경 비트만 이용 → 최근 사용 여부를 근사적 판단. 구현 비용을 줄인다.
        </details>

---

<b>추가: 프레임 할당 방식</b>

<details>

- 물리 메모리 프레임 → 각 프로세스에 how to 배분 결정
- 페이지 폴트 빈도, 전체 시스템 성능 변화
- 고정 할당 방식, 동적 할당 방식
    - 고정 할당
        - 프로세스 생성 시 일정 수의 프레임 할당
        - 실행 중에 변경 없음
    - 동적 할당
        - 프로세스의 요구에 따라 프레임 수 증가/감소
        - 실행 중에 변경
        - 실제 운영체제는 동적 할당을 사용
        - 메모리 사용 급증하는 프로세스에 더 많은 프레임 할당
        - 반대: 프레임을 회수

</details>


### 쓰래싱Thrashing

- 시스템 성능이 급격히 저하 by 페이지 폴트가 1) 연속적으로 발생 2) 매우 짧은 시간 간격

- How?
    1) 메모리 공간이 부족 = 프레임 수 충분하지 않음
    2) 많은 프로세스가 동시에 실행
    3) 페이지 폴트 빈번하게 발생
    4) 스와핑 작업 과도하게 증가
    5) 스와핑 잦아질수록 메모리에 입출력 부하 증가
    6) CPU: 실제 연산보다 페이지 교체 작업에 더 많은 시간 소비
    7) 오히려 CPU 사용률 감소
    8) OS: 해결하기 위해 더 많은 프로세스를 메모리에 up 시도
    9) 페이지 폴트 더 발생!
    10) 악순환 반복

<details><summary>추가</summary>

- 메모리 부족도 문제 맞으나 더 큰 문제 존재
- 이슈: 시스템의 다중 프로그래밍 정도 (multiprogramming level) (하드코딩인가?)
- 스레싱이 발생하는 임계 구간
    - 실행 중인 프로세스 수 증가할 수록 CPU 이용률: 일정 수준까지 증가
    - 임계점 넘어서면 페이피 폴트 빈도 급격 상승 + CPU 이용률 감소함
    - 해당 지점이 스레싱이 발생하는 임계 구간임
- OS: 해당 현상 방지 위해 다중 프로그래밍 정도를 의도적으로 제한
- if needed, 일부 프로세스 스왑 아웃 → 실행 대상 수 자체를 줄인다

</details>

### 워킹 셋

- 쓰래싱에 대한 소프트웨어적 해결책
- 의미: 페이지의 집합 of 특정 시간 구간 동안 한 프로세스가 실제로 참조한
- 해당 집합: 해당 프로세스가 정상적으로 실행되기 위해 (반드시 메모리에 상주할) 최소 페이지 집합
- OS: 워킹 셋 크기를 기준으로 충분한 프레임 수 할당
- 해당 값이 메모리 전체 용량 초과? → 일부 프로세스 일시 중단 = 스레싱 발생 예방
- ∴ 페이지 폴트 빈도 안정적 유지 = CPU & 메모리 효율적 사용

<details>

- 워킹 셋 모델은 Δ (델타: 시간) 동안 프로세스가 실제로 참조한 페이지의 집합을 기반으로 함.
- 델타값이 너무 작다 = 순간적 페이지 변동에 과도하게 민감
- 델타값 너무 크다 = 필요하지 않은 페이지까지 워킹 셋 포함 = 프레임 낭비 발생
- ∴ 운영체제: 적절한 델타값 유지 (실험적/통계적 방식)
- 유사한 개념: 페이지 폴트 빈도(Pace Fault Frequency)
- PFF: 페이지 폴트 발생 빈도 기준, 프레임 할당량 동적으로 조절
    - PFF 과도하게 높다 = 프레임 추가 할당
    - 너무 작다 = 프레임 회수


</details>