
### 메모리
저장 자원: CPU가 직접 접근해 데이터를 읽고 쓰는 저장 자원

- 계층 구조: 하단 참조
- 실행 상태에 있는 프로세스: 반드시 메인 메모리에 적재.
- 실행되지 않는 프로세스: 보조 기억장치의 스왑 영역에 저장
- 스와핑: 프로세스의 상태 변화에 따라 메인 메모리 ↔ 보조 저장장치 사이에서 교환/이동
- 메모리 할당 방식: 고정 분할/가변 분할
    - 운영 체제는 여러 개의 프로세스를 메모리에 올려야 한다.
    - 이 때 메모리 할당 방식을 사용해 프로세스마다 필요한 공간을 배정함.
    - 고정 분할 방식
        - 메모리를 미리 일정한 크기로 자름 → 각 프로세스에 하나의 분할 영역을 할당하는 방식
        - 구현은 단순
        - 프로세스 크기와 분할 크기가 맞지 않으면? ▷ `내부 단편화` 발생 = 메모리 낭비 ↑
    - 가변 분할 방식
        - 프로세스 크기에 맞춰 메모리 공간을 동적으로 할당 (=그때그때)
        - 메모리 활용률 ↑ (Compare to 고정 분할)
        - 외부 단편화가 발생 염려
    - `외부 단편화`?
       - 가변 분할 방식에서 보통 발생.
       - 상황: 메모리에 사용 가능한 총 공간은 존재하는데 (1~10) 연속된 큰 블록이 부족해 새 프로세스를 적재하지 못함
       - (4 정도 사이즈 되는 것이 들어가야 하는데, 1~3/ 4공란 5공란 6공란 7 사용 8공란 9공란 10공란 이런식)
       - 해결법: 메모리 압축 / `가상 메모리 기법`
- 가상 메모리: 실제 물리 메모리RAM의 크기보다 큰 프로세스를 실행할 수 있게 만듬
    - 당장 필요한 부분(프로세스)만 RAM 적재 ▷ 나머지는 보조기억장치에 보관
    - 사용자/프로그램: 매우 큰 연속 메모리 사용하는 것처럼 인식
    - 실제: OS가 물리 메모리/디스크 공간 함께 사용해 `가상 주소 공간`을 제공
- 페이징 기법
    - 가상 메모리 구현하는 고정 분할 기반 방식
    - 논리 주소 공간 | 물리 주소 공간   나눌 때 모두 동일한 크기의 블록으로
    - 논리 주소 공간의 단위를 `페이지`
    - 물리 주소 공간의 단위를 `프레임` (물리프리 논리책)
    - 각 프로세스의 페이지(논리 주소 공간 블록) → 메인 메모리의 프레임(물리)에 불연속 할당될 수 있음
    - 연속되게 보이고 싶겠지? 연속된 주소로 보이기 위해 페이지 테이블을 통해 주소 변환 발생
    - 주소를 통해 참조 참조 참조 된다는 소리인가?
    - 외부 단편화는 해결하지만, Issue: 페이지 크기보다 작은 데이터 남으면 ▷ `내부 단편화`
- 페이지 테이블 레지스터
    - 현재 실행 중인 프로세스의 페이지 테이블이 메모리의 어디에 있음? 알려주는 레지스터
    - CPU는 논리 주소 → 물리 주소로 변환 때 해당 레지스터를 기준으로 페이지 테이블 엔트리를 참조
    - 1 페이지 테이블 엔트리 = 해당 페이지의 N개 속성 저장
    - 속성: 접근 비트, 변경 비트, 유효 비트, 보호 비트
        - 접근 비트: 해당 페이지가 메모리에 올라온 이후 실제로 참조된 적이 있는지 나타냄
        - 변경 비트: 페이지의 내용이 수정되었는가? 나타냄. 페이지가 디스크로 내려갈 때 다시 기록해야 하는가? 결정 기준
        - 유효 비트: 해당 페이지는 현재 메인 메모리에 존재하는가? 디스크에 존재하는가? 나타냄
        - 보호 비트: 페이지에 대한 읽기/쓰기/실행 권한 지정 → 메모리 보호 기능 수행
- 페이지드 세그멘테이션
    - 가상 메모리 관리 방식 = 세그멘테이션 + 페이징 기법(둘을 결합)
    - 프로그램의 논리 구조에 따라 분할 = 코드 | 데이터 | 스택 (이런 세그먼트로 분할)
    - 각 세그먼트를 다시 일정한 크기의 페이지로 나누어 관리
    - 장점: 세그멘테이션의 논리적 구조 반영. 페이징의 외부 단편화 제거
    - 단점: 주소 변환 과정 복잡. 관리 비용 ↑

- 이런 메모리 관리 비법: 한정된 물리 메모리 자원을 다수의 프로세스가 안정적으로 공유하기 위한 핵시 ㅁ기술.
- 시스템 성능, 안정성, 확장성에 영향을 미침

### 메모리의 계층 구조

- 계층 구조: 속도, 용량, 비용 차이에 따라 계층 구조로 구성. 레지스터, 캐시, 메인 메모리(RAM), 보조기억장치
- 레지스터: CPU 내부에 위치, Quickest, 용량 극히 작음
- 캐시 메모리(L1,L2,L3)
    - 고속 완충 장치: 주기억장치 접근 지연을 줄이기 위해
    - 지역성 원리, L1-L2-L3 설계, 캐시히트/캐시미스, 캐시 일관성, 쓰기 방식(반영 방식)
    - <details> <summary>상세</summary>
        
        - CPU - RAM 사이 위치하는 고속 완충 저장 장치.
        - 메모리 접근 지연Latency 최소화 → 전체 시스템 성능 ↑
        - 지역성Locality 원리 기반으로 동작: 시간적/공간적
        - 두 성질을 이용해 프로그램 실행 시 반복적으로 참조되는 코드와 데이터 우선적으로 저장
            - 시간적 지역성: 최근 사용한 데이터가 가까운 미래에도 다시 사용될 가능성이 크다
            - 공간적 지역성: 어떤 메모리 주소가 접근 → 인접 주소도 곧 접근될 가능성이 크다
        - L1,L2,L3 캐시: 속도·용량·비용 균형을 고려해 설계
            - L1: CPU 내부 존재. 가장 빠른 접근 속도, 용량 매우 작음
            - L2: L1과 L2 사이 ▷ L1보다 느리지만 용량 더 크며, L3보다 빠르지만 용량 작음. 코어별로 분리되어 있거나/공유되거나
            - L3: 여러 코어가 공유하는 형태. 가장 느린 접근 속도, 용량 가장 큼.
        - CPU가 접근하는 순서: L1 (캐시 히트) → L2  → L3 → 없을 시 메인 메모리에서 데이터 가져옴(캐시 미스)
        - 캐시 미스일 경우 메모리 접근 지연 ↑
        - 캐시 히트율이 좋아야겠지? 히트율 높을수록 CPU는 대기 없이 연산 수행
        - 캐시 일관성
            - 멀티코어에서 중요
            - 각 캐시 라인의 상태를 공유/수정/무효화 등의 상태로 관리해 모든 코어가 동일한 메모리 값을 보도록 보장함
            - 여러 개의 CPU가 각자 독립된 캐시 보유 시, 한 코어가 데이터 수정 → 다른 코어의 (캐시에 저장된) 동일 데이터와 불일치 발생
            - 이를 방지하기 위해 캐시 일관성 프로토콜 사용(예: MESI) → 상태를 관리
        - 쓰기 방식에 따른 구분: Write Through, Write Back
            - Write Through: 캐시 쓰기 연산 발생 → 메인 메모리(RAM)에도 즉시 반영
            - Write Back: 캐시 쓰기 연산 발생 → 우선 캐시에만 반영 → 캐시 라인 교체될 때 메인 메모리에 반영
            - 데이터 일관성 높음(Good), 메모리 접근 회수 증가(Bad) VS 성능 우수(Good), 데이터 손실 위험 - 전원 장애(Bad)

    </details>

- 메인 메모리
    - 실행 중인 프로그램과 데이터를 저장하는 공간

- 보조기억장치
    - 전원이 꺼져도 데이터가 유지되는 대용량 저장 장치

### 요구 페이징,

###